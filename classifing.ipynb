{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "sw = nltk.corpus.stopwords.words('english')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punc = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word in punc:\n",
    "    sw.append(word)\n",
    "sw.append('br')\n",
    "    \n",
    "stopwords = set(sw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    reviews = []\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        t = f.readlines()\n",
    "    for line in t:\n",
    "        ids, rating, review = line.split(',', 2)\n",
    "        reviews.append([ids, rating, review.strip().lower()])\n",
    "    df = pd.DataFrame(reviews, columns=['id', 'rating', 'review'])\n",
    "    df['rating'] = df.rating.astype(\"int\")\n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = read_file('./pos_train_reviews.csv')\n",
    "pos['sent'] = 1\n",
    "pos['rating'] = pos.rating.astype(\"int\")\n",
    "pos.loc[pos.rating == 0, 'rating'] = 10\n",
    "\n",
    "\n",
    "neg = read_file('./neg_train_reviews.csv')\n",
    "neg['sent'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pos.append(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 4)"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_pos = read_file('./pos_test_reviews.csv')\n",
    "test_pos['sent'] = 1\n",
    "test_pos['rating'] = test_pos.rating.astype(\"int\")\n",
    "test_pos.loc[test_pos.rating == 0, 'rating'] = 10\n",
    "\n",
    "\n",
    "test_neg = read_file('./neg_test_reviews.csv')\n",
    "test_neg['sent'] = 0\n",
    "\n",
    "test = test_pos.append(test_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = list(train.review)\n",
    "test_data = list(test.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english',\n",
    "                       strip_accents='unicode',\n",
    "                        # ngram_range=(1,2),\n",
    "                       max_df=0.8\n",
    "                       )\n",
    "cv = CountVectorizer(stop_words=stopwords,\n",
    "                       strip_accents='unicode',\n",
    "                        # ngram_range=(1,2),\n",
    "                       # max_df=0.7\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = cv.fit_transform(train_data)\n",
    "y = train.sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = cv.transform(test_data)\n",
    "y_test = test.sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/base.py:175: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  args, varargs, kw, default = inspect.getargspec(init)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.3, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.78      0.83     13981\n",
      "          1       0.76      0.86      0.81     11019\n",
      "\n",
      "avg / total       0.82      0.82      0.82     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(nb.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import operator as op\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_word_set(filename):\n",
    "    \"\"\"\n",
    "    Gets the dictionary from our preprocessed dataset\n",
    "    \"\"\"\n",
    "    with open (filename, 'r') as f:\n",
    "        tmp = f.readlines()\n",
    "        tmp = [line.rstrip() for line in tmp]   \n",
    "    word_split = lambda x: x.split()[2].split(':')[0]\n",
    "    return set(map(word_split, t))\n",
    "\n",
    "\n",
    "def split_list(x):\n",
    "    t = x.split('\\t')\n",
    "    i = eval(t[0])[0]\n",
    "    rating = eval(t[0])[1]\n",
    "    word, count = t[1].split(':')\n",
    "    return i, rating, word, int(count)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    " \n",
    "    reviews = []\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        t = f.readlines()\n",
    "    for line in t:\n",
    "        ids, rating, review = line.split(',', 2)\n",
    "        reviews.append([ids, rating, review.strip().lower()])\n",
    "    df = pd.DataFrame(reviews, columns=['id', 'rating', 'review'])\n",
    "    df['rating'] = df.rating.astype(\"int\")\n",
    "    return df\n",
    "    \n",
    "\n",
    "def data_maker(_data):\n",
    "    \"\"\"\n",
    "    hacky method to pivot the data from 'long' to 'wide' for each review.\n",
    "    Args:\n",
    "        _data: unzipped group-by'd list of stuff\n",
    "    Returns:\n",
    "        list of dictionaries with k: v s.t. k = word, v = count(word). \n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for row in _data:\n",
    "        z = {}\n",
    "        for line in row:\n",
    "            k, v = line[1].split(':')\n",
    "            z[k] = int(v)\n",
    "        res.append(z)\n",
    "    return res\n",
    "\n",
    "\n",
    "def read_file(filename):\n",
    "    \"\"\"\n",
    "    preprocesses some of the weirdness out of the format we saved to\n",
    "    Returns:\n",
    "        list of all lines in the files according to: [(id, rating), 'word:<count>']\n",
    "    \"\"\"\n",
    "    with open (filename, 'r') as f:\n",
    "        tmp = f.readlines()\n",
    "        tmp = [line.rstrip() for line in tmp]\n",
    "        split = lambda x: x.split('\\t')\n",
    "        tmp = list(map(split, tmp))\n",
    "        tup, val = list(zip(*tmp))\n",
    "        # this bit changes all the string tuples to python tuples. \n",
    "        tmp = list(zip(map(eval, tup), val))\n",
    "    return tmp\n",
    "\n",
    "\n",
    "def make_train_data(data):\n",
    "    \"\"\" \n",
    "    Uses Sklearn's helper method to vectorize a list of dictionary features into a scipy \n",
    "    sparse matrix for training\n",
    "    Returns:\n",
    "        tuple of data, sparse_matrix\n",
    "    \"\"\"\n",
    "    dv = DictVectorizer()\n",
    "    _data = dict(zip(ids, res))\n",
    "    return _data, dv.fit_transform(data)\n",
    "    \n",
    "\n",
    "get_neg_ids = lambda x: x[0][1] < 5\n",
    "get_pos_ids = lambda x: x[0][1] > 5\n",
    "\n",
    "# gets a list of sentiment scores\n",
    "get_sent = lambda x: 1 if x[1] > 5 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# raw_train = read_file('./train_mr_output.csv')\n",
    "grouped = it.groupby(raw_train, op.itemgetter(0))\n",
    "\n",
    "train_g = [(k, list(g)) for k, g in grouped]\n",
    "ids, _tmp = zip(*train_g)\n",
    "\n",
    "train = data_maker(_tmp)\n",
    "train, X = make_train_data(train)\n",
    "y = list(map(get_sent, ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# raw_test = read_file('./test_mr_output.csv')\n",
    "test_grouped = it.groupby(raw_test, op.itemgetter(0))\n",
    "\n",
    "test_g = [(k, list(g)) for k, g in test_grouped]\n",
    "test_ids, test_tmp = zip(*test_g)\n",
    "\n",
    "test = data_maker(test_tmp)\n",
    "test, X_test = make_train_data(test)\n",
    "y_test = list(map(get_sent, test_ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.,  1.,  1.,  2.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  2.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  2.,  1.,  2.,  1.,  2.,  1.,  1.,  5.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  2.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  2.,  1.,  1.,\n",
       "        1.,  1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  2.,  1.,  1.,\n",
       "        1.,  2.,  1.,  1.,  1.,  1.,  1.,  1.,  4.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  2.,  1.,  1.,  3.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,2].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x74830 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2464517 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = it.groupby(raw_train, op.itemgetter(0))\n",
    "\n",
    "# g = [(k, list(g)) for k, g in grouped]\n",
    "ids, _tmp = zip(*g)\n",
    "\n",
    "train = data_maker(_tmp)\n",
    "train, X = make_train_data(train)\n",
    "y = list(map(get_sent, ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb = MultinomialNB(alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/base.py:175: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  args, varargs, kw, default = inspect.getargspec(init)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.3, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 743,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/base.py:175: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  args, varargs, kw, default = inspect.getargspec(init)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-772-83a9794767c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \"\"\"\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m         return (safe_sparse_dot(X, self.feature_log_prob_.T)\n\u001b[0m\u001b[1;32m    616\u001b[0m                 + self.class_log_prior_)\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \"\"\"\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"toarray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "print(classification_report(nb.predict(X_test), y_test))\n",
    "print(classification_report(sgd.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sknn.mlp import Classifier, Layer\n",
    "\n",
    "nn = Classifier(\n",
    "    layers=[\n",
    "        Layer(\"Rectifier\", units=10, pieces=2),\n",
    "        Layer(\"Softmax\")],\n",
    "    learning_rate=0.001,\n",
    "    n_iter=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
